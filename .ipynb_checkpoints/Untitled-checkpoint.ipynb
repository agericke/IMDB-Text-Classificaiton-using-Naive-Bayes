{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from math import log, exp\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: In your final submission, set `ALPHA`\n",
    "#       to the value you think will be optimal for predicting on\n",
    "#       unseen data\n",
    "# Keep this as a package global variable\n",
    "ALPHA = 1.0\n",
    "# End TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBText:\n",
    "    \"\"\"Class to represent text, exposing generator function for words\n",
    "    \"\"\"\n",
    "    def __init__(self, idnum, text):\n",
    "        self.text = text\n",
    "        self.idnum = idnum\n",
    "\n",
    "    def get_words(self):\n",
    "        # Preprocess text\n",
    "        cleaned = bs(self.text, features=\"html.parser\").text\n",
    "        for word in cleaned.strip().split():\n",
    "            word = re.sub(r\"^\\W+\", \"\", word)\n",
    "            word = re.sub(r\"\\W+$\", \"\", word)\n",
    "            if word:\n",
    "                yield word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBReader:\n",
    "    \"\"\"Utility class for reading IMDB data\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        dir_contents = os.listdir(data_dir)\n",
    "        assert \"pos\" in dir_contents and \"neg\" in dir_contents, \\\n",
    "            \"Could not find IMDB data in {}\".format(data_dir)\n",
    "\n",
    "\n",
    "    def get_texts(self, subset):\n",
    "        \"\"\"Generator function over texts in subset ('pos' or 'neg') of data\n",
    "        \"\"\"\n",
    "        assert subset in [\"pos\", \"neg\"], \\\n",
    "            \"Only data subsets 'pos' or 'neg' may be selected\"\n",
    "        for textfile in os.listdir(os.path.join(self.data_dir, subset)):\n",
    "            if textfile[-4:] == \".txt\":\n",
    "                with open(os.path.join(self.data_dir, subset, textfile),\n",
    "                          encoding=\"utf-8\") as f:\n",
    "                    yield IMDBText(textfile[:-4], f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \"\"\"Naive Bayes text categorization model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.train(data)\n",
    "\n",
    "    def train(self, data):\n",
    "        \"\"\"Train model by collecting counts from training corpus\n",
    "        \"\"\"\n",
    "\n",
    "        # Counts of words in positive-/negative-class texts\n",
    "        # w_count[w][y=pos]\n",
    "        self.count_positive = Counter()\n",
    "        # w_count[w][y=neg]\n",
    "        self.count_negative = Counter()\n",
    "\n",
    "        # Total number of reviews for each category\n",
    "        # d_count[y=pos]\n",
    "        self.num_positive_reviews = 0\n",
    "        # d_count[y=neg]\n",
    "        self.num_negative_reviews = 0\n",
    "\n",
    "        # Total number of words in positive/negative reviews\n",
    "        # w_count[y=pos]\n",
    "        self.total_positive_words = 0\n",
    "        # w_count[y=neg]\n",
    "        self.total_negative_words = 0\n",
    "\n",
    "        # Class priors (logprobs)\n",
    "        # log(P(y=pos))\n",
    "        self.p_positive = 0.0\n",
    "        # log(P(y=neg))\n",
    "        self.p_negative = 0.0\n",
    "\n",
    "        # TODO: Iterate through texts and collect count statistics initialized above\n",
    "        #       `self.count_<positive/negative>`\n",
    "        #       `self.num_<positive/negative>_reviews`\n",
    "        #       `self.total_<positive/negative>_words`\n",
    "        for i, text in enumerate(data.get_texts(\"pos\")):\n",
    "            #\n",
    "            self.num_positive_reviews += 1;\n",
    "            for i, word in enumerate(text.get_words()):\n",
    "                self.count_positive.update([word]);\n",
    "            #\n",
    "            if i % 100 == 0:\n",
    "                sys.stdout.write(\".\")\n",
    "\n",
    "        self.total_positive_words = sum(self.count_positive.values());\n",
    "        print();\n",
    "\n",
    "        for i, text in enumerate(data.get_texts(\"neg\")):\n",
    "            #\n",
    "            self.num_negative_reviews += 1;\n",
    "            for i, word in enumerate(text.get_words()):\n",
    "                self.count_negative.update([word]);\n",
    "            #\n",
    "            if i % 100 == 0:\n",
    "                sys.stdout.write(\".\");\n",
    "        \n",
    "        self.total_negative_words = sum(self.count_negative.values());\n",
    "        print()\n",
    "        # End TODO\n",
    "\n",
    "        # Calculate derived statistics\n",
    "        self.vocab = set(list(self.count_negative.keys())\n",
    "                         + list(self.count_positive.keys()))\n",
    "        self.p_positive = log(float(self.num_positive_reviews)) \\\n",
    "            - log(float(self.num_positive_reviews + self.num_negative_reviews))\n",
    "        self.p_negative = log(float(self.num_negative_reviews)) \\\n",
    "            - log(float(self.num_positive_reviews + self.num_negative_reviews))\n",
    "\n",
    "    def predict(self, data, alpha=1.0):\n",
    "        \"\"\"For each text\n",
    "           - append the text id (file basename) to `text_ids`\n",
    "           - append the predicted label (1.0 or -1.0) to `pred_labels`\n",
    "           - append the correct (gold) label (1.0 or -1.0) to `gold_labels`\n",
    "           - append the probability of the positive (1.0) class to `pred_probs`\n",
    "        \"\"\"\n",
    "        text_ids = []\n",
    "        pred_labels = []\n",
    "        pred_probs = []\n",
    "        gold_labels = []\n",
    "\n",
    "        for classval in [\"pos\", \"neg\"]:\n",
    "            for text in data.get_texts(classval):\n",
    "                text_ids.append(text.idnum)\n",
    "                if classval == \"pos\":\n",
    "                    gold_labels.append(1.0)\n",
    "                else:\n",
    "                    gold_labels.append(-1.0)\n",
    "                if len(text_ids) % 100 == 0:\n",
    "                    sys.stdout.write(\".\")\n",
    "\n",
    "                # TODO: Implement naive Bayes probability estimation to calculate class probabilities\n",
    "                #       and predicted labels for each text in the test set.\n",
    "                #\n",
    "                #       Work using logprobs instead of probabilities in order to avoid numerical underflow.\n",
    "                #       Remember that the model treats multiple occurrences of the same word within a text\n",
    "                #       as independent events\n",
    "                words = [];\n",
    "                sum_positive = 0;\n",
    "                sum_negative = 0;\n",
    "                for word in text.get_words():\n",
    "                    if word not in words:\n",
    "                        words.append(word);\n",
    "                        # log(P(Pos|X))\n",
    "                        sum_positive += log(self.count_positive[word] + alpha) - log(self.total_positive_words+alpha*len(self.vocab));\n",
    "                        # log(P(Neg|X))\n",
    "                        sum_negative += log(self.count_negative[word] + alpha) - log(self.total_negative_words+alpha*len(self.vocab));\n",
    "\n",
    "                sum_positive += self.p_positive;\n",
    "                sum_negative += self.p_negative;\n",
    "                # End TODO\n",
    "\n",
    "                # Get P(Y|X) by normalizing across log(P(Y,X)) for both values of Y\n",
    "                # 1) Get K = log(P(Pos|X) + P(Neg|X))\n",
    "                normalization_factor = self.log_sum(sum_positive, sum_negative)\n",
    "                # 2) Calculate P(Pos|X) = e^(log(P(Pos,X)) - K)\n",
    "                predicted_prob_positive = exp(sum_positive - normalization_factor)\n",
    "                # 3) Get P(Neg|X) = P(Neg|X) = e^(log(P(Neg,X)) - K)\n",
    "                predicted_prob_negative = 1.0 - predicted_prob_positive\n",
    "\n",
    "                pred_probs.append(predicted_prob_positive)\n",
    "                if predicted_prob_positive > predicted_prob_negative:\n",
    "                    pred_labels.append(1.0)\n",
    "                else:\n",
    "                    pred_labels.append(-1.0)\n",
    "            print()\n",
    "\n",
    "        return text_ids, gold_labels, pred_labels, pred_probs\n",
    "\n",
    "    def log_sum(self, logx, logy):\n",
    "        \"\"\"Utility function to compute $log(exp(logx) + exp(logy))$\n",
    "        while avoiding numerical issues\n",
    "        \"\"\"\n",
    "        m = max(logx, logy)\n",
    "        return m + log(exp(logx - m) + exp(logy - m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 - Define datadirs of data\n",
    "TRAIN_DATA_DIR = \"hw3_data/train\"\n",
    "TEST_DATA_DIR = \"hw3_data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing parameters\n",
      "........................................................................................................\n",
      "[('the', 149313), ('and', 85542), ('a', 79811), ('of', 75635), ('to', 65616)]\n",
      "[('also.I', 1), ('actions,style,songs', 1), ('high..This', 1), ('hibernation,Rajini', 1), ('time.With', 1)]\n",
      "12500\n",
      "2898191\n",
      ".........................................................................................\n"
     ]
    }
   ],
   "source": [
    "# 1 - Compute parameters for Naive Bayes\n",
    "print(\"Computing parameters\")\n",
    "NB = NaiveBayes(IMDBReader(TRAIN_DATA_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test set\n",
      ".....................................................................\n",
      ".....................................................................\n"
     ]
    }
   ],
   "source": [
    "# 2 - Make predictions\n",
    "print(\"Predicting on test set\")\n",
    "TEST_IDS, GOLD_LABELS, PRED_LABELS, PRED_PROBS = NB.predict(IMDBReader(TEST_DATA_DIR), alpha=ALPHA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(pred_labels, true_labels):\n",
    "    \"\"\"\n",
    "    Function for obtaining the accuracy of our predictions\n",
    "    Params:\n",
    "        - pred_labels: predicted labels by our model.\n",
    "        - true_labels: true labels of the texts.\n",
    "    Returns:\n",
    "        A float representing the accuracy of the predictions made.\n",
    "    \"\"\"\n",
    "    return np.sum(np.equal(pred_labels, true_labels)) / float(len(true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n",
      "Test accuracy: 82.95%\n"
     ]
    }
   ],
   "source": [
    "# 3 - Evaluate Results and obtain accuracy\n",
    "print(\"Evaluating\")\n",
    "ACCURACY = evaluate_predictions(PRED_LABELS, GOLD_LABELS)\n",
    "print(\"Test accuracy: {:.2f}%\".format(100 * ACCURACY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-12-652fbb0d26d4>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-652fbb0d26d4>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def evaluate_case(alpha=1.0):\n",
    "    print(\"Predicting on test set for alpha=%f\" % alpha)\n",
    "    TEST_IDS, GOLD_LABELS, PRED_LABELS, PRED_PROBS = NB.predict(IMDBReader(TEST_DATA_DIR), alpha=alpha)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "11\n",
      "21\n",
      "31\n",
      "41\n",
      "51\n",
      "61\n",
      "71\n",
      "81\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10,10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
